#!/usr/bin/env python3
"""
3 Venturi Harmonic Autonomous Self-Calibration Tool
Advanced harmonic analysis and autonomous calibration for L.I.F.E THEORY

Copyright 2025 - Sergio Paya Borrull
Revolutionary harmonic Venturi control with autonomous calibration
"""

import asyncio
import logging
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
from scipy import signal as scipy_signal
from scipy.fft import fft, fftfreq, ifft

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class HarmonicAnalyzer:
    """Advanced harmonic analysis for Venturi gates with enhanced FFT processing and EEG integration"""

    def __init__(self, sampling_rate: float = 1000.0):
        self.sampling_rate = sampling_rate
        self.harmonic_history: List[Dict[str, Any]] = []

        # Enhanced harmonic detection parameters for latest optimization
        self.harmonic_threshold = 0.08  # More sensitive detection
        self.fundamental_detection_window = 3.0  # Hz - Narrower window for precision

        # Enhanced resonance detection parameters
        self.resonance_q_factor = 15.0  # Higher Q for better resonance isolation
        self.resonance_threshold = 0.12  # Lower threshold for better sensitivity

        # New adaptive frequency tracking for autonomous calibration
        self.adaptive_tracking = True
        self.frequency_history = []
        self.max_history_length = 100

        # EEG-specific frequency bands for neural integration
        self.eeg_bands = {
            "delta": (0.5, 4.0),
            "theta": (4.0, 8.0),
            "alpha": (8.0, 13.0),
            "beta": (13.0, 30.0),
            "gamma": (30.0, 50.0),
        }

        # VR pre-rendering frequency bands for synchronized processing
        self.vr_bands = {
            "low_latency": (1.0, 10.0),  # Critical for VR motion
            "visual_sync": (10.0, 25.0),  # Visual frame sync
            "haptic_feedback": (25.0, 45.0),  # Haptic response
        }

        # ML pipeline integration parameters
        self.ml_feature_bands = {
            "spectral_power": (0.5, 50.0),
            "coherence": (8.0, 30.0),
            "phase_coupling": (4.0, 13.0),
        }

    def analyze_harmonics(self, signal_data: np.ndarray) -> Dict[str, Any]:
        """
        Enhanced harmonic analysis with FFT-based frequency domain processing

        Args:
            signal_data: Input signal for harmonic analysis

        Returns:
            Comprehensive harmonic analysis results with EEG/ML/VR integration
        """
        try:
            # Enhanced FFT analysis with zero-padding for better resolution
            N = len(signal_data)
            N_padded = 2 ** int(np.ceil(np.log2(N * 2)))

            # Apply Hann window for better spectral analysis
            windowed_signal = signal_data * np.hanning(N)

            # Enhanced FFT with zero-padding
            fft_data = fft(windowed_signal, n=N_padded)
            freqs = fftfreq(N_padded, 1 / self.sampling_rate)

            # Power spectral density with normalization
            psd = np.abs(fft_data) ** 2
            psd = psd / np.sum(psd)  # Normalize

            # Enhanced dominant frequency detection with adaptive threshold
            dominant_freqs = self._find_dominant_frequencies_enhanced(freqs, psd)

            # Harmonic series detection with improved algorithm
            fundamental_freq = dominant_freqs[0] if dominant_freqs else 0.0
            harmonics = self._detect_harmonic_series_enhanced(
                freqs, psd, fundamental_freq
            )

            # Enhanced harmonic distortion analysis
            thd = self._calculate_thd_enhanced(harmonics)

            # Enhanced resonance analysis with Q-factor calculation
            resonance_info = self._analyze_resonance_enhanced(freqs, psd)

            # EEG band power analysis for neural integration
            eeg_band_powers = self._calculate_eeg_band_powers(freqs, psd)

            # VR synchronization features for pre-rendering pipeline
            vr_sync_features = self._calculate_vr_sync_features(freqs, psd)

            # ML feature extraction for enhanced learning pipeline
            ml_features = self._calculate_ml_features(freqs, psd, harmonics)

            # Enhanced quality metrics
            quality_metrics = {
                "snr": self._calculate_snr(signal_data),
                "spectral_entropy": self._calculate_spectral_entropy(psd),
                "harmonic_purity": self._calculate_harmonic_purity(psd, harmonics),
                "frequency_stability": self._calculate_frequency_stability(),
            }

            analysis_result = {
                "timestamp": datetime.now().isoformat(),
                "fundamental_frequency": fundamental_freq,
                "dominant_frequencies": dominant_freqs[:5],  # Top 5
                "harmonic_series": harmonics,
                "total_harmonic_distortion": thd,
                "resonance_info": resonance_info,
                "eeg_band_powers": eeg_band_powers,
                "vr_sync_features": vr_sync_features,
                "ml_features": ml_features,
                "quality_metrics": quality_metrics,
                "spectral_centroid": self._calculate_spectral_centroid(freqs, psd),
                "spectral_rolloff": self._calculate_spectral_rolloff(freqs, psd),
                "harmonic_ratio": self._calculate_harmonic_ratio(psd, harmonics),
                "harmonic_coherence": self._calculate_harmonic_coherence(harmonics),
            }

            # Store in enhanced history for autonomous learning
            self.harmonic_history.append(analysis_result)
            if len(self.harmonic_history) > 1000:  # Increased history limit
                self.harmonic_history.pop(0)

            # Update adaptive frequency tracking
            if self.adaptive_tracking:
                self._update_frequency_history(fundamental_freq)

            return analysis_result

        except Exception as e:
            logger.error(f"Harmonic analysis failed: {e}")
            return {}

    def _find_dominant_frequencies_enhanced(
        self, freqs: np.ndarray, psd: np.ndarray, num_peaks: int = 10
    ) -> List[float]:
        """Enhanced dominant frequency detection with adaptive thresholding"""
        positive_freq_mask = freqs > 0
        pos_freqs = freqs[positive_freq_mask]
        pos_psd = psd[positive_freq_mask]

        # Adaptive threshold based on signal characteristics
        median_power = np.median(pos_psd)
        adaptive_threshold = max(median_power * 3.0, np.max(pos_psd) * 0.05)

        # Enhanced peak detection with prominence
        peaks, properties = scipy_signal.find_peaks(
            pos_psd,
            height=adaptive_threshold,
            prominence=adaptive_threshold * 0.5,
            distance=int(len(pos_psd) * 0.01),  # Minimum distance between peaks
        )

        # Sort by combined score of magnitude and prominence
        if len(peaks) > 0:
            peak_scores = pos_psd[peaks] * properties["prominences"]
            sorted_indices = np.argsort(peak_scores)[::-1]
            top_peaks = peaks[sorted_indices[:num_peaks]]
            return [pos_freqs[peak] for peak in top_peaks]

        return []

    def _detect_harmonic_series_enhanced(
        self, freqs: np.ndarray, psd: np.ndarray, fundamental: float
    ) -> Dict[int, float]:
        """Enhanced harmonic series detection with improved accuracy"""
        harmonics = {}

        if fundamental <= 0:
            return harmonics

        # Look for harmonics up to 15th order with tighter tolerance
        for harmonic_order in range(1, 16):
            target_freq = fundamental * harmonic_order

            # Skip frequencies above Nyquist
            if target_freq >= self.sampling_rate / 2:
                continue

            # Find closest frequency bin with interpolation
            freq_diff = np.abs(freqs - target_freq)
            closest_idx = np.argmin(freq_diff)

            # Enhanced tolerance based on fundamental frequency
            tolerance = max(self.fundamental_detection_window, fundamental * 0.02)

            if freq_diff[closest_idx] <= tolerance:
                # Interpolate for better accuracy
                if closest_idx > 0 and closest_idx < len(psd) - 1:
                    # Quadratic interpolation around peak
                    y1, y2, y3 = psd[closest_idx - 1 : closest_idx + 2]
                    a = (y1 - 2 * y2 + y3) / 2
                    b = (y3 - y1) / 2

                    if a != 0:
                        peak_offset = -b / (2 * a)
                        interpolated_power = y2 + a * peak_offset**2 + b * peak_offset
                        harmonics[harmonic_order] = float(interpolated_power)
                    else:
                        harmonics[harmonic_order] = float(psd[closest_idx])
                else:
                    harmonics[harmonic_order] = float(psd[closest_idx])

        return harmonics

    def _calculate_eeg_band_powers(
        self, freqs: np.ndarray, psd: np.ndarray
    ) -> Dict[str, float]:
        """Calculate power in EEG frequency bands for neural integration"""
        band_powers = {}

        for band_name, (low_freq, high_freq) in self.eeg_bands.items():
            # Find frequency indices within band
            band_mask = (freqs >= low_freq) & (freqs <= high_freq)

            if np.any(band_mask):
                band_power = np.sum(psd[band_mask])
                band_powers[band_name] = float(band_power)
            else:
                band_powers[band_name] = 0.0

        return band_powers

    def _calculate_vr_sync_features(
        self, freqs: np.ndarray, psd: np.ndarray
    ) -> Dict[str, float]:
        """Calculate VR synchronization features for pre-rendering pipeline"""
        vr_features = {}

        for band_name, (low_freq, high_freq) in self.vr_bands.items():
            band_mask = (freqs >= low_freq) & (freqs <= high_freq)

            if np.any(band_mask):
                band_freqs = freqs[band_mask]
                band_psd = psd[band_mask]

                # Calculate centroid frequency for synchronization
                if np.sum(band_psd) > 0:
                    centroid = np.sum(band_freqs * band_psd) / np.sum(band_psd)
                    vr_features[f"{band_name}_centroid"] = float(centroid)

                    # Calculate bandwidth for stability assessment
                    variance = np.sum(
                        ((band_freqs - centroid) ** 2) * band_psd
                    ) / np.sum(band_psd)
                    bandwidth = np.sqrt(variance)
                    vr_features[f"{band_name}_bandwidth"] = float(bandwidth)

                    # Calculate power for amplitude control
                    vr_features[f"{band_name}_power"] = float(np.sum(band_psd))
                else:
                    vr_features[f"{band_name}_centroid"] = 0.0
                    vr_features[f"{band_name}_bandwidth"] = 0.0
                    vr_features[f"{band_name}_power"] = 0.0

        return vr_features

    def _calculate_ml_features(
        self, freqs: np.ndarray, psd: np.ndarray, harmonics: Dict[int, float]
    ) -> Dict[str, float]:
        """Calculate ML features for enhanced learning pipeline"""
        ml_features = {}

        for feature_name, (low_freq, high_freq) in self.ml_feature_bands.items():
            band_mask = (freqs >= low_freq) & (freqs <= high_freq)

            if np.any(band_mask):
                band_freqs = freqs[band_mask]
                band_psd = psd[band_mask]

                # Feature extraction for ML pipeline
                ml_features[f"{feature_name}_mean"] = float(np.mean(band_psd))
                ml_features[f"{feature_name}_std"] = float(np.std(band_psd))
                ml_features[f"{feature_name}_skew"] = float(
                    self._calculate_skewness(band_psd)
                )
                ml_features[f"{feature_name}_kurtosis"] = float(
                    self._calculate_kurtosis(band_psd)
                )

                # Peak characteristics
                peaks, _ = scipy_signal.find_peaks(band_psd)
                ml_features[f"{feature_name}_peak_count"] = len(peaks)

                if len(peaks) > 0:
                    ml_features[f"{feature_name}_peak_mean"] = float(
                        np.mean(band_psd[peaks])
                    )
                    ml_features[f"{feature_name}_peak_max"] = float(
                        np.max(band_psd[peaks])
                    )
                else:
                    ml_features[f"{feature_name}_peak_mean"] = 0.0
                    ml_features[f"{feature_name}_peak_max"] = 0.0

        # Harmonic features for ML
        if harmonics:
            harmonic_powers = list(harmonics.values())
            ml_features["harmonic_energy"] = float(np.sum(harmonic_powers))
            ml_features["harmonic_entropy"] = float(
                self._calculate_entropy(harmonic_powers)
            )
            ml_features["harmonic_complexity"] = len(harmonics)

        return ml_features

    def _update_frequency_history(self, fundamental_freq: float):
        """Update frequency history for autonomous tracking"""
        self.frequency_history.append(fundamental_freq)
        if len(self.frequency_history) > self.max_history_length:
            self.frequency_history = self.frequency_history[-self.max_history_length :]

    def _calculate_frequency_stability(self) -> float:
        """Calculate frequency stability metric"""
        if len(self.frequency_history) < 2:
            return 1.0

        # Calculate coefficient of variation
        mean_freq = np.mean(self.frequency_history)
        std_freq = np.std(self.frequency_history)

        if mean_freq > 0:
            cv = std_freq / mean_freq
            stability = 1.0 / (1.0 + cv)  # Higher stability = lower variation
            return float(stability)

        return 0.0

    def _calculate_harmonic_coherence(self, harmonics: Dict[int, float]) -> float:
        """Calculate harmonic coherence for quality assessment"""
        if len(harmonics) < 2:
            return 0.0

        # Calculate coherence based on harmonic power distribution
        harmonic_orders = sorted(harmonics.keys())
        harmonic_powers = [harmonics[order] for order in harmonic_orders]

        # Expected harmonic decay (1/n relationship)
        expected_powers = [harmonic_powers[0] / order for order in harmonic_orders]

        # Calculate correlation between actual and expected
        if np.std(harmonic_powers) > 0 and np.std(expected_powers) > 0:
            correlation = np.corrcoef(harmonic_powers, expected_powers)[0, 1]
            return float(max(0.0, correlation))

        return 0.0

    # Enhanced helper methods for latest optimization
    def _calculate_skewness(self, data: np.ndarray) -> float:
        """Calculate skewness of data distribution"""
        if len(data) < 3:
            return 0.0

        mean = np.mean(data)
        std = np.std(data)

        if std == 0:
            return 0.0

        normalized = (data - mean) / std
        skewness = np.mean(normalized**3)
        return skewness

    def _calculate_kurtosis(self, data: np.ndarray) -> float:
        """Calculate kurtosis of data distribution"""
        if len(data) < 4:
            return 0.0

        mean = np.mean(data)
        std = np.std(data)

        if std == 0:
            return 0.0

        normalized = (data - mean) / std
        kurtosis = np.mean(normalized**4) - 3  # Excess kurtosis
        return kurtosis

    def _calculate_entropy(self, data: np.ndarray) -> float:
        """Calculate entropy of data distribution"""
        if len(data) == 0:
            return 0.0

        # Normalize to probability distribution
        data_normalized = np.array(data) / np.sum(data)

        # Remove zeros to avoid log(0)
        data_normalized = data_normalized[data_normalized > 0]

        if len(data_normalized) == 0:
            return 0.0

        entropy = -np.sum(data_normalized * np.log2(data_normalized))
        return entropy

    def _calculate_snr(self, signal: np.ndarray) -> float:
        """Calculate Signal-to-Noise Ratio"""
        if len(signal) < 2:
            return 0.0

        # Estimate noise as high-frequency components
        nyquist = self.sampling_rate / 2
        high_cutoff = min(nyquist * 0.8, 100)  # Hz

        try:
            # Design high-pass filter
            sos = scipy_signal.butter(
                4, high_cutoff / nyquist, btype="high", output="sos"
            )
            noise_estimate = scipy_signal.sosfilt(sos, signal)

            signal_power = np.mean(signal**2)
            noise_power = np.mean(noise_estimate**2)

            if noise_power > 0:
                snr_db = 10 * np.log10(signal_power / noise_power)
                return max(0.0, snr_db)
            else:
                return 60.0  # Very high SNR
        except:
            # Fallback: use signal variance as proxy
            signal_power = np.var(signal)
            return max(0.0, 10 * np.log10(max(signal_power, 1e-10)))

    def _calculate_spectral_entropy(self, psd: np.ndarray) -> float:
        """Calculate spectral entropy for signal complexity assessment"""
        return self._calculate_entropy(psd)

    def _calculate_harmonic_purity(
        self, psd: np.ndarray, harmonics: Dict[int, float]
    ) -> float:
        """Calculate harmonic purity metric"""
        if not harmonics:
            return 0.0

        total_power = np.sum(psd)
        harmonic_power = sum(harmonics.values())

        if total_power > 0:
            purity = harmonic_power / total_power
            return min(1.0, purity)

        return 0.0

    def _calculate_thd_enhanced(self, harmonics: Dict[int, float]) -> float:
        """Enhanced Total Harmonic Distortion calculation"""
        if not harmonics or 1 not in harmonics:
            return 0.0

        fundamental_power = harmonics[1]
        harmonic_powers = [power for order, power in harmonics.items() if order > 1]

        if fundamental_power <= 0:
            return 0.0

        # Weighted THD calculation
        weighted_harmonics = []
        for order, power in harmonics.items():
            if order > 1:
                # Weight by 1/order for realistic harmonic contribution
                weighted_power = power / order
                weighted_harmonics.append(weighted_power)

        if weighted_harmonics:
            thd = np.sqrt(sum(weighted_harmonics)) / fundamental_power
            return float(min(1.0, thd))  # Cap at 100%

        return 0.0

    def _analyze_resonance_enhanced(
        self, freqs: np.ndarray, psd: np.ndarray
    ) -> Dict[str, float]:
        """Enhanced resonance analysis with Q-factor calculation"""
        # Enhanced peak detection with adaptive threshold
        median_power = np.median(psd)
        threshold = max(median_power * 5.0, np.max(psd) * 0.08)

        peaks, properties = scipy_signal.find_peaks(
            psd, prominence=threshold, height=threshold
        )

        resonance_info = {
            "num_resonances": len(peaks),
            "primary_resonance": 0.0,
            "resonance_quality": 0.0,
            "bandwidth": 0.0,
            "q_factor": 0.0,
            "resonance_strength": 0.0,
        }

        if len(peaks) > 0:
            # Primary resonance (highest peak)
            primary_idx = peaks[np.argmax(psd[peaks])]
            resonance_info["primary_resonance"] = float(freqs[primary_idx])
            resonance_info["resonance_strength"] = float(psd[primary_idx])

            # Enhanced Q-factor estimation
            try:
                peak_power = psd[primary_idx]
                half_power = peak_power / np.sqrt(2)  # -3dB points

                # Find bandwidth using more sophisticated method
                left_idx = primary_idx
                right_idx = primary_idx

                # Search for half-power points
                while left_idx > 0 and psd[left_idx] > half_power:
                    left_idx -= 1
                while right_idx < len(psd) - 1 and psd[right_idx] > half_power:
                    right_idx += 1

                if left_idx != right_idx:
                    bandwidth = freqs[right_idx] - freqs[left_idx]
                    resonance_info["bandwidth"] = float(bandwidth)

                    # Q-factor calculation
                    if bandwidth > 0:
                        q_factor = freqs[primary_idx] / bandwidth
                        resonance_info["q_factor"] = float(q_factor)

                        # Quality assessment (higher Q = better resonance)
                        quality = min(1.0, q_factor / self.resonance_q_factor)
                        resonance_info["resonance_quality"] = float(quality)

            except Exception as e:
                logger.warning(f"Q-factor calculation failed: {e}")

        return resonance_info

    def _calculate_thd(self, harmonics: Dict[int, float]) -> float:
        """Calculate Total Harmonic Distortion"""
        if not harmonics or 1 not in harmonics:
            return 0.0

        fundamental_power = harmonics[1]
        harmonic_powers = [power for order, power in harmonics.items() if order > 1]

        if fundamental_power <= 0:
            return 0.0

        thd = np.sqrt(sum(harmonic_powers)) / fundamental_power
        return float(thd)

    def _analyze_resonance(
        self, freqs: np.ndarray, psd: np.ndarray
    ) -> Dict[str, float]:
        """Analyze resonance characteristics"""
        # Find resonant frequencies (local maxima)
        peaks, properties = scipy_signal.find_peaks(psd, prominence=np.max(psd) * 0.05)

        resonance_info = {
            "num_resonances": len(peaks),
            "primary_resonance": 0.0,
            "resonance_quality": 0.0,
            "bandwidth": 0.0,
        }

        if len(peaks) > 0:
            # Primary resonance (highest peak)
            primary_idx = peaks[np.argmax(psd[peaks])]
            resonance_info["primary_resonance"] = float(freqs[primary_idx])

            # Quality factor estimation (Q = f0/bandwidth)
            try:
                # Find half-power points
                peak_power = psd[primary_idx]
                half_power = peak_power / 2

                # Find bandwidth
                left_idx = primary_idx
                right_idx = primary_idx

                while left_idx > 0 and psd[left_idx] > half_power:
                    left_idx -= 1
                while right_idx < len(psd) - 1 and psd[right_idx] > half_power:
                    right_idx += 1

                bandwidth = freqs[right_idx] - freqs[left_idx]
                resonance_info["bandwidth"] = float(abs(bandwidth))

                if bandwidth > 0:
                    quality = resonance_info["primary_resonance"] / bandwidth
                    resonance_info["resonance_quality"] = float(quality)

            except Exception as e:
                logger.warning(f"Resonance quality calculation failed: {e}")

        return resonance_info

    def _calculate_spectral_centroid(self, freqs: np.ndarray, psd: np.ndarray) -> float:
        """Calculate spectral centroid (brightness measure)"""
        positive_mask = freqs > 0
        pos_freqs = freqs[positive_mask]
        pos_psd = psd[positive_mask]

        if np.sum(pos_psd) <= 0:
            return 0.0

        centroid = np.sum(pos_freqs * pos_psd) / np.sum(pos_psd)
        return float(centroid)

    def _calculate_spectral_rolloff(
        self, freqs: np.ndarray, psd: np.ndarray, rolloff_percent: float = 0.85
    ) -> float:
        """Calculate spectral rolloff frequency"""
        positive_mask = freqs > 0
        pos_freqs = freqs[positive_mask]
        pos_psd = psd[positive_mask]

        total_energy = np.sum(pos_psd)
        if total_energy <= 0:
            return 0.0

        cumulative_energy = np.cumsum(pos_psd)
        rolloff_threshold = total_energy * rolloff_percent

        rolloff_idx = np.where(cumulative_energy >= rolloff_threshold)[0]
        if len(rolloff_idx) > 0:
            return float(pos_freqs[rolloff_idx[0]])

        return float(pos_freqs[-1])  # Return highest frequency if not found

    def _calculate_harmonic_ratio(
        self, psd: np.ndarray, harmonics: Dict[int, float]
    ) -> float:
        """Calculate ratio of harmonic to total energy"""
        total_energy = np.sum(psd)
        harmonic_energy = sum(harmonics.values())

        if total_energy <= 0:
            return 0.0

        return float(harmonic_energy / total_energy)


class VenturiHarmonicGate:
    """Individual Venturi gate with enhanced harmonic processing capabilities"""

    def __init__(self, gate_id: str, target_frequency: float = 10.0):
        self.gate_id = gate_id
        self.target_frequency = target_frequency
        self.resonance_factor = 1.0
        self.harmonic_gain = 1.0
        self.phase_offset = 0.0

        # Enhanced adaptive parameters for latest optimization
        self.adaptation_rate = 0.01
        self.performance_history: List[float] = []
        self.learning_rate = 0.005  # For autonomous calibration
        self.stability_threshold = 0.95

        # Harmonic analyzer with enhanced settings
        self.harmonic_analyzer = HarmonicAnalyzer()

        # Enhanced processing parameters
        self.frequency_tolerance = 0.5  # Hz
        self.resonance_enhancement = True
        self.phase_alignment = True
        self.amplitude_normalization = True

        # EEG integration parameters
        self.eeg_mode = False  # Enable for EEG signal processing
        self.neural_band_weights = {
            "delta": 1.0,
            "theta": 1.2,
            "alpha": 1.5,
            "beta": 1.3,
            "gamma": 1.1,
        }

        # VR pre-rendering integration
        self.vr_mode = False  # Enable for VR synchronization
        self.vr_latency_compensation = 2.0  # ms
        self.vr_frame_sync = 60.0  # Hz

        # ML pipeline integration
        self.ml_mode = False  # Enable for ML feature extraction
        self.ml_feature_cache = {}
        self.ml_update_interval = 10  # samples

        # Autonomous calibration state
        self.calibration_state = {
            "is_calibrated": False,
            "calibration_accuracy": 0.0,
            "last_calibration": None,
            "calibration_iterations": 0,
        }

        logger.info(
            f"Enhanced Harmonic Venturi Gate {gate_id} initialized at {target_frequency}Hz"
        )

    def process_harmonic_signal(
        self, signal_data: np.ndarray, processing_mode: str = "standard"
    ) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        Enhanced signal processing with harmonic Venturi effects

        Args:
            signal_data: Input signal
            processing_mode: 'standard', 'eeg', 'vr', or 'ml'

        Returns:
            Tuple of (processed_signal, enhanced_processing_metrics)
        """
        try:
            # Enhanced harmonic analysis
            harmonic_analysis = self.harmonic_analyzer.analyze_harmonics(signal_data)

            # Mode-specific preprocessing
            if processing_mode == "eeg":
                self.eeg_mode = True
                signal_data = self._preprocess_eeg_signal(signal_data)
            elif processing_mode == "vr":
                self.vr_mode = True
                signal_data = self._preprocess_vr_signal(signal_data)
            elif processing_mode == "ml":
                self.ml_mode = True
                self._update_ml_features(harmonic_analysis)

            # Apply enhanced harmonic Venturi processing
            processed = self._apply_harmonic_venturi_effect_enhanced(
                signal_data, harmonic_analysis, processing_mode
            )

            # Enhanced performance assessment
            performance = self._assess_harmonic_performance_enhanced(
                signal_data, processed, harmonic_analysis, processing_mode
            )
            self.performance_history.append(performance)

            # Autonomous adaptation with mode-specific parameters
            self._adapt_harmonic_parameters_enhanced(
                harmonic_analysis, performance, processing_mode
            )

            # Enhanced processing metrics
            processing_metrics = {
                "gate_id": self.gate_id,
                "processing_mode": processing_mode,
                "harmonic_analysis": harmonic_analysis,
                "performance_score": performance,
                "resonance_factor": self.resonance_factor,
                "harmonic_gain": self.harmonic_gain,
                "phase_offset": self.phase_offset,
                "target_frequency": self.target_frequency,
                "calibration_state": self.calibration_state,
                "frequency_stability": self._calculate_frequency_stability(),
                "adaptation_status": self._get_adaptation_status(),
                "quality_metrics": self._calculate_gate_quality_metrics(
                    signal_data, processed
                ),
            }

            # Mode-specific metric additions
            if self.eeg_mode:
                processing_metrics["eeg_band_optimization"] = (
                    self._calculate_eeg_optimization_metrics(harmonic_analysis)
                )
            if self.vr_mode:
                processing_metrics["vr_sync_metrics"] = self._calculate_vr_sync_metrics(
                    harmonic_analysis
                )
            if self.ml_mode:
                processing_metrics["ml_features"] = self.ml_feature_cache

            return processed, processing_metrics

        except Exception as e:
            logger.error(
                f"Enhanced harmonic processing failed for gate {self.gate_id}: {e}"
            )
            return signal_data, {"error": str(e), "gate_id": self.gate_id}

    def _apply_harmonic_venturi_effect(
        self, signal: np.ndarray, harmonic_info: Dict[str, Any]
    ) -> np.ndarray:
        """Apply harmonic-enhanced Venturi effect"""

        # Stage 1: Resonance amplification
        resonance_enhanced = self._apply_resonance_amplification(signal, harmonic_info)

        # Stage 2: Harmonic shaping
        harmonic_shaped = self._apply_harmonic_shaping(
            resonance_enhanced, harmonic_info
        )

        # Stage 3: Phase-aligned processing
        phase_processed = self._apply_phase_alignment(harmonic_shaped, harmonic_info)

        return phase_processed

    def _apply_resonance_amplification(
        self, signal: np.ndarray, harmonic_info: Dict[str, Any]
    ) -> np.ndarray:
        """Amplify signal components near resonance frequency"""

        # Create resonance filter
        sampling_rate = 1000.0  # Assume 1kHz sampling
        nyquist = sampling_rate / 2

        # Design bandpass filter around target frequency
        low_freq = max(0.1, self.target_frequency - 2.0) / nyquist
        high_freq = min(0.99, self.target_frequency + 2.0) / nyquist

        try:
            # Butterworth bandpass filter
            b, a = scipy_signal.butter(4, [low_freq, high_freq], btype="band")

            # Apply filter
            filtered = scipy_signal.filtfilt(b, a, signal)

            # Amplify resonant components
            amplified = signal + filtered * (self.resonance_factor - 1.0)

            return amplified

        except Exception as e:
            logger.warning(f"Resonance amplification failed: {e}")
            return signal

    def _apply_harmonic_shaping(
        self, signal: np.ndarray, harmonic_info: Dict[str, Any]
    ) -> np.ndarray:
        """Shape harmonic content for optimal processing"""

        # FFT processing
        fft_data = fft(signal)
        freqs = fftfreq(len(signal), 1 / 1000.0)  # 1kHz sampling

        # Apply harmonic gain
        for i, freq in enumerate(freqs):
            if abs(freq) > 0:
                # Calculate harmonic order
                if self.target_frequency > 0:
                    harmonic_order = abs(freq) / self.target_frequency

                    # Apply gain based on harmonic relationship
                    if abs(harmonic_order - round(harmonic_order)) < 0.1:
                        # This is close to a harmonic
                        fft_data[i] *= self.harmonic_gain

        # Convert back to time domain
        shaped_signal = np.real(ifft(fft_data))

        return shaped_signal

    def _apply_phase_alignment(
        self, signal: np.ndarray, harmonic_info: Dict[str, Any]
    ) -> np.ndarray:
        """Apply phase alignment for optimal Venturi effect"""

        # Create phase-shifted version
        fft_data = fft(signal)

        # Apply phase offset
        phase_shift = np.exp(1j * self.phase_offset)
        fft_data *= phase_shift

        # Convert back to time domain
        phase_aligned = np.real(ifft(fft_data))

        return phase_aligned

    def _assess_harmonic_performance(
        self,
        input_signal: np.ndarray,
        output_signal: np.ndarray,
        harmonic_info: Dict[str, Any],
    ) -> float:
        """Assess harmonic processing performance"""

        try:
            # Analyze output harmonics
            output_analysis = self.harmonic_analyzer.analyze_harmonics(output_signal)

            # Performance metrics
            harmonic_enhancement = 0.0
            resonance_alignment = 0.0
            distortion_control = 1.0

            # 1. Harmonic enhancement at target frequency
            if "harmonic_series" in output_analysis:
                output_harmonics = output_analysis["harmonic_series"]
                if 1 in output_harmonics:  # Fundamental
                    harmonic_enhancement = min(
                        1.0, output_harmonics[1] / (np.var(output_signal) + 1e-6)
                    )

            # 2. Resonance alignment
            if "primary_resonance" in output_analysis["resonance_info"]:
                primary_res = output_analysis["resonance_info"]["primary_resonance"]
                frequency_error = abs(primary_res - self.target_frequency) / (
                    self.target_frequency + 1e-6
                )
                resonance_alignment = max(0.0, 1.0 - frequency_error)

            # 3. Distortion control (lower THD is better)
            if "total_harmonic_distortion" in output_analysis:
                thd = output_analysis["total_harmonic_distortion"]
                distortion_control = max(0.0, 1.0 - min(1.0, thd))

            # Combined performance score
            performance = (
                0.4 * harmonic_enhancement
                + 0.3 * resonance_alignment
                + 0.3 * distortion_control
            )

            return float(np.clip(performance, 0.0, 1.0))

        except Exception as e:
            logger.warning(f"Performance assessment failed: {e}")
            return 0.5  # Default performance

    def _adapt_harmonic_parameters(
        self, harmonic_info: Dict[str, Any], performance: float
    ):
        """Autonomous adaptation of harmonic parameters"""

        # Performance-based adaptation
        performance_delta = performance - 0.7  # Target performance = 0.7

        # Adapt resonance factor
        resonance_adjustment = self.adaptation_rate * performance_delta
        self.resonance_factor = np.clip(
            self.resonance_factor + resonance_adjustment, 0.5, 2.0
        )

        # Adapt harmonic gain
        if len(self.performance_history) >= 5:
            recent_trend = (
                np.mean(self.performance_history[-5:])
                - np.mean(self.performance_history[-10:-5])
                if len(self.performance_history) >= 10
                else 0
            )

            if recent_trend > 0:
                # Performance improving, continue current direction
                self.harmonic_gain = np.clip(self.harmonic_gain * 1.01, 0.5, 2.0)
            else:
                # Performance declining, adjust
                self.harmonic_gain = np.clip(self.harmonic_gain * 0.99, 0.5, 2.0)

        # Adapt phase offset based on resonance info
        if "resonance_info" in harmonic_info:
            resonance_quality = harmonic_info["resonance_info"].get(
                "resonance_quality", 1.0
            )
            if resonance_quality < 5.0:  # Low quality, adjust phase
                self.phase_offset += 0.1 * self.adaptation_rate
                self.phase_offset = self.phase_offset % (2 * np.pi)


class ThreeVenturiHarmonicSystem:
    """Complete 3-Venturi Harmonic Autonomous Self-Calibration System with Enhanced Optimization"""

    def __init__(self, target_frequencies: Optional[List[float]] = None):

        # Enhanced harmonic frequencies for optimal neural processing
        if target_frequencies is None:
            # Optimized for EEG/ML/VR integration
            target_frequencies = [8.5, 25.5, 42.0]  # Alpha, Beta, Gamma ranges

        # Initialize 3 enhanced harmonic Venturi gates
        self.gates = {
            "harmonic_gate_1": VenturiHarmonicGate("gate_1", target_frequencies[0]),
            "harmonic_gate_2": VenturiHarmonicGate("gate_2", target_frequencies[1]),
            "harmonic_gate_3": VenturiHarmonicGate("gate_3", target_frequencies[2]),
        }

        # Enhanced system state with autonomous learning capabilities
        self.calibration_state = {
            "is_calibrated": False,
            "calibration_score": 0.0,
            "last_calibration": None,
            "calibration_iterations": 0,
            "auto_recalibration": True,
            "learning_rate": 0.01,
            "stability_metric": 0.0,
            "convergence_threshold": 0.001,
        }

        # Enhanced system performance tracking
        self.system_performance_history: List[Dict[str, Any]] = []

        # EEG/ML/VR Integration parameters
        self.integration_modes = {
            "eeg_preprocessing": False,
            "ml_pipeline": False,
            "vr_prerendering": False,
        }

        # Enhanced coordination parameters
        self.coordination_params = {
            "synchronization_accuracy": 0.95,
            "phase_coherence_threshold": 0.9,
            "amplitude_balance_factor": 1.0,
            "inter_gate_coupling": 0.3,
        }

        # Autonomous optimization parameters
        self.optimization_config = {
            "adaptive_threshold": 0.85,
            "max_iterations": 100,
            "convergence_patience": 10,
            "performance_window": 50,
            "quality_threshold": 0.9,
        }

        # Real-time monitoring
        self.monitoring_active = False
        self.real_time_metrics = {}

        logger.info(
            f"Enhanced 3-Venturi Harmonic System initialized with frequencies: {target_frequencies}"
        )
        logger.info("üöÄ Ready for EEG/ML/VR pipeline integration")

    def autonomous_calibration(
        self, calibration_signal: np.ndarray, target_performance: float = 0.85
    ) -> Dict[str, Any]:
        """
        Perform autonomous self-calibration of the 3-Venturi harmonic system

        Args:
            calibration_signal: Reference signal for calibration
            target_performance: Target performance threshold

        Returns:
            Calibration results and status
        """

        logger.info("üîß Starting autonomous 3-Venturi harmonic calibration...")

        calibration_results = {
            "started": datetime.now().isoformat(),
            "target_performance": target_performance,
            "iterations": 0,
            "gate_performance": {},
            "system_performance": 0.0,
            "convergence_achieved": False,
            "calibration_successful": False,
        }

        max_iterations = 50
        convergence_threshold = 0.01

        try:
            for iteration in range(max_iterations):
                # Process signal through all gates
                processed_signal, gate_metrics = self.process_harmonic_signal(
                    calibration_signal
                )

                # Calculate system performance
                system_performance = self._calculate_system_performance(gate_metrics)

                # Store performance
                calibration_results["gate_performance"] = {
                    gate_id: metrics["performance_score"]
                    for gate_id, metrics in gate_metrics.items()
                }
                calibration_results["system_performance"] = system_performance
                calibration_results["iterations"] = iteration + 1

                # Check convergence
                if iteration > 5:
                    recent_performances = [
                        entry["system_performance"]
                        for entry in self.system_performance_history[-5:]
                    ]
                    performance_variance = np.var(recent_performances)

                    if performance_variance < convergence_threshold:
                        calibration_results["convergence_achieved"] = True
                        logger.info(
                            f"‚úÖ Convergence achieved after {iteration + 1} iterations"
                        )
                        break

                # Check if target performance reached
                if system_performance >= target_performance:
                    calibration_results["calibration_successful"] = True
                    logger.info(
                        f"üéØ Target performance reached: {system_performance:.3f}"
                    )
                    break

                # Store system performance
                self.system_performance_history.append(
                    {
                        "timestamp": datetime.now().isoformat(),
                        "iteration": iteration,
                        "system_performance": system_performance,
                        "gate_performances": calibration_results[
                            "gate_performance"
                        ].copy(),
                    }
                )

                # Autonomous optimization (gates adapt automatically)
                self._optimize_harmonic_coordination()

                # Brief pause for adaptation
                time.sleep(0.01)

            # Final assessment
            final_performance = calibration_results["system_performance"]

            if final_performance >= target_performance:
                self.calibration_state["is_calibrated"] = True
                calibration_results["calibration_successful"] = True
                logger.info(f"‚úÖ Calibration successful: {final_performance:.3f}")
            else:
                logger.warning(
                    f"‚ö†Ô∏è Calibration incomplete: {final_performance:.3f} < {target_performance}"
                )

            # Update calibration state
            self.calibration_state.update(
                {
                    "calibration_score": final_performance,
                    "last_calibration": datetime.now().isoformat(),
                    "calibration_iterations": calibration_results["iterations"],
                }
            )

            calibration_results["completed"] = datetime.now().isoformat()

            return calibration_results

        except Exception as e:
            logger.error(f"Autonomous calibration failed: {e}")
            calibration_results["error"] = str(e)
            return calibration_results

    def autonomous_calibration_enhanced(
        self,
        calibration_signal: np.ndarray,
        target_performance: float = 0.90,
        processing_mode: str = "standard",
    ) -> Dict[str, Any]:
        """
        Enhanced autonomous self-calibration with EEG/ML/VR optimization

        Args:
            calibration_signal: Reference signal for calibration
            target_performance: Enhanced target performance threshold (90%)
            processing_mode: 'standard', 'eeg', 'ml', 'vr', or 'multi'

        Returns:
            Enhanced calibration results with detailed optimization metrics
        """

        logger.info(
            f"üöÄ Starting ENHANCED autonomous 3-Venturi harmonic calibration..."
        )
        logger.info(
            f"üéØ Target performance: {target_performance:.1%} | Mode: {processing_mode}"
        )

        calibration_results = {
            "started": datetime.now().isoformat(),
            "target_performance": target_performance,
            "processing_mode": processing_mode,
            "iterations": 0,
            "gate_performance": {},
            "system_performance": 0.0,
            "convergence_achieved": False,
            "calibration_successful": False,
            "optimization_history": [],
            "frequency_stability": 0.0,
            "harmonic_coherence": 0.0,
            "phase_synchronization": 0.0,
            "adaptive_learning_rate": self.calibration_state["learning_rate"],
            "eeg_optimization": {},
            "ml_features": {},
            "vr_sync_metrics": {},
        }

        # Enhanced optimization parameters
        max_iterations = self.optimization_config["max_iterations"]
        convergence_threshold = self.calibration_state["convergence_threshold"]
        convergence_patience = self.optimization_config["convergence_patience"]

        # Initialize enhanced adaptive learning
        best_performance = 0.0
        patience_counter = 0
        learning_decay = 0.95

        try:
            for iteration in range(max_iterations):
                # Enhanced processing with mode-specific optimization
                if processing_mode == "multi":
                    # Multi-mode processing for comprehensive optimization
                    processed_signal, gate_metrics = self._process_multi_mode(
                        calibration_signal
                    )
                elif processing_mode == "eeg":
                    # EEG-optimized processing
                    processed_signal, gate_metrics = self._process_eeg_optimized(
                        calibration_signal
                    )
                elif processing_mode == "ml":
                    # ML pipeline optimized processing
                    processed_signal, gate_metrics = self._process_ml_optimized(
                        calibration_signal
                    )
                elif processing_mode == "vr":
                    # VR pre-rendering optimized processing
                    processed_signal, gate_metrics = self._process_vr_optimized(
                        calibration_signal
                    )
                else:
                    # Standard enhanced processing
                    processed_signal, gate_metrics = self.process_harmonic_signal(
                        calibration_signal
                    )

                # Enhanced system performance calculation
                system_performance = self._calculate_system_performance_enhanced(
                    gate_metrics
                )

                # Calculate advanced stability metrics
                frequency_stability = self._calculate_system_frequency_stability()
                harmonic_coherence = self._calculate_system_harmonic_coherence(
                    gate_metrics
                )
                phase_sync = self._calculate_phase_synchronization(gate_metrics)

                # Store comprehensive optimization data
                iteration_data = {
                    "iteration": iteration + 1,
                    "system_performance": system_performance,
                    "frequency_stability": frequency_stability,
                    "harmonic_coherence": harmonic_coherence,
                    "phase_synchronization": phase_sync,
                    "gate_performance": {
                        gate_id: metrics.get("performance_score", 0.0)
                        for gate_id, metrics in gate_metrics.items()
                    },
                    "learning_rate": self.calibration_state["learning_rate"],
                }

                calibration_results["optimization_history"].append(iteration_data)
                calibration_results.update(
                    {
                        "gate_performance": iteration_data["gate_performance"],
                        "system_performance": system_performance,
                        "frequency_stability": frequency_stability,
                        "harmonic_coherence": harmonic_coherence,
                        "phase_synchronization": phase_sync,
                        "iterations": iteration + 1,
                        "adaptive_learning_rate": self.calibration_state[
                            "learning_rate"
                        ],
                    }
                )

                # Enhanced convergence detection with multi-criteria
                performance_improved = (
                    system_performance > best_performance + convergence_threshold
                )
                stability_achieved = frequency_stability >= 0.9
                coherence_achieved = harmonic_coherence >= 0.85
                sync_achieved = phase_sync >= 0.8

                if performance_improved and stability_achieved:
                    best_performance = system_performance
                    patience_counter = 0
                    logger.info(f"üìà New best performance: {best_performance:.1%}")
                else:
                    patience_counter += 1

                # Adaptive learning rate with intelligent decay
                if patience_counter > 5:
                    self.calibration_state["learning_rate"] *= learning_decay
                    calibration_results["adaptive_learning_rate"] = (
                        self.calibration_state["learning_rate"]
                    )
                    if iteration % 10 == 0:
                        logger.info(
                            f"üìâ Learning rate adjusted: {self.calibration_state['learning_rate']:.6f}"
                        )

                # Enhanced target achievement check (multi-criteria)
                targets_met = all(
                    [
                        system_performance >= target_performance,
                        frequency_stability >= 0.9,
                        harmonic_coherence >= 0.85,
                        phase_sync >= 0.8,
                    ]
                )

                if targets_met:
                    calibration_results.update(
                        {"convergence_achieved": True, "calibration_successful": True}
                    )
                    logger.info(
                        f"üéâ ENHANCED calibration SUCCESS! Performance: {system_performance:.1%}"
                    )
                    logger.info(
                        f"‚ú® Stability: {frequency_stability:.1%}, Coherence: {harmonic_coherence:.1%}, Sync: {phase_sync:.1%}"
                    )
                    break

                # Intelligent early stopping
                if patience_counter >= convergence_patience:
                    logger.info(
                        f"‚èπÔ∏è Enhanced early stopping after {iteration + 1} iterations"
                    )
                    break

                # Progress logging with enhanced metrics
                if iteration % 5 == 0:
                    logger.info(
                        f"üìä Iter {iteration + 1}: Perf={system_performance:.1%}, "
                        f"Stab={frequency_stability:.1%}, Coh={harmonic_coherence:.1%}, "
                        f"Sync={phase_sync:.1%}"
                    )

                # Autonomous optimization step
                self._optimize_harmonic_coordination_enhanced(
                    gate_metrics, processing_mode
                )

            # Final enhanced assessment
            final_success = (
                calibration_results["system_performance"] >= target_performance * 0.9
            )
            calibration_results["calibration_successful"] = final_success

            # Update enhanced system state
            self.calibration_state.update(
                {
                    "is_calibrated": final_success,
                    "calibration_score": calibration_results["system_performance"],
                    "last_calibration": datetime.now().isoformat(),
                    "calibration_iterations": calibration_results["iterations"],
                    "stability_metric": calibration_results["frequency_stability"],
                }
            )

            # Integration mode specific results
            if processing_mode in ["eeg", "multi"]:
                calibration_results["eeg_optimization"] = (
                    self._get_eeg_optimization_results()
                )
            if processing_mode in ["ml", "multi"]:
                calibration_results["ml_features"] = self._get_ml_feature_results()
            if processing_mode in ["vr", "multi"]:
                calibration_results["vr_sync_metrics"] = self._get_vr_sync_results()

            success_emoji = "üéâ" if final_success else "‚ö†Ô∏è"
            logger.info(
                f"{success_emoji} Enhanced calibration completed: {final_success}"
            )
            logger.info(
                f"üìà Final metrics - Performance: {calibration_results['system_performance']:.1%}, "
                f"Stability: {calibration_results['frequency_stability']:.1%}"
            )

            return calibration_results

        except Exception as e:
            logger.error(f"Enhanced autonomous calibration failed: {e}")
            calibration_results["error"] = str(e)
            return calibration_results

    def process_harmonic_signal(
        self, signal_data: np.ndarray
    ) -> Tuple[np.ndarray, Dict[str, Dict[str, Any]]]:
        """
        Process signal through 3-Venturi harmonic system

        Args:
            signal_data: Input signal

        Returns:
            Tuple of (processed_signal, gate_metrics)
        """

        gate_metrics = {}
        current_signal = signal_data.copy()

        # Process through each gate sequentially
        for gate_id, gate in self.gates.items():
            processed_signal, metrics = gate.process_harmonic_signal(current_signal)
            gate_metrics[gate_id] = metrics
            current_signal = processed_signal

        return current_signal, gate_metrics

    def _calculate_system_performance(
        self, gate_metrics: Dict[str, Dict[str, Any]]
    ) -> float:
        """Calculate overall system performance"""

        gate_performances = [
            metrics.get("performance_score", 0.0) for metrics in gate_metrics.values()
        ]

        if not gate_performances:
            return 0.0

        # Weighted average with emphasis on consistency
        avg_performance = np.mean(gate_performances)
        performance_std = np.std(gate_performances)

        # Penalty for inconsistency between gates
        consistency_bonus = max(0.0, 1.0 - performance_std)

        system_performance = 0.8 * avg_performance + 0.2 * consistency_bonus

        return float(np.clip(system_performance, 0.0, 1.0))

    def _optimize_harmonic_coordination(self):
        """Optimize coordination between harmonic gates"""

        # Calculate inter-gate harmonic relationships
        target_freqs = [gate.target_frequency for gate in self.gates.values()]

        # Ensure harmonic relationships
        fundamental = min(target_freqs)

        for gate_id, gate in self.gates.items():
            # Adjust target frequency to maintain harmonic relationships
            if gate.target_frequency > fundamental:
                harmonic_ratio = gate.target_frequency / fundamental
                ideal_ratio = round(harmonic_ratio)

                # Gradually adjust toward ideal harmonic ratio
                ideal_frequency = fundamental * ideal_ratio
                frequency_error = abs(gate.target_frequency - ideal_frequency)

                if frequency_error > 0.5:  # If significantly off
                    adjustment = 0.1 * (ideal_frequency - gate.target_frequency)
                    gate.target_frequency += adjustment

    def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive system status"""

        status = {
            "calibration_state": self.calibration_state.copy(),
            "gate_status": {},
            "system_performance": 0.0,
            "harmonic_coordination": {},
            "recent_performance_trend": "stable",
        }

        # Gate status
        for gate_id, gate in self.gates.items():
            status["gate_status"][gate_id] = {
                "target_frequency": gate.target_frequency,
                "resonance_factor": gate.resonance_factor,
                "harmonic_gain": gate.harmonic_gain,
                "phase_offset": gate.phase_offset,
                "recent_performance": (
                    np.mean(gate.performance_history[-5:])
                    if len(gate.performance_history) >= 5
                    else 0.0
                ),
            }

        # System performance
        if self.system_performance_history:
            recent_performances = [
                entry["system_performance"]
                for entry in self.system_performance_history[-10:]
            ]
            status["system_performance"] = np.mean(recent_performances)

            # Performance trend
            if len(recent_performances) >= 5:
                early_avg = np.mean(
                    recent_performances[: len(recent_performances) // 2]
                )
                late_avg = np.mean(recent_performances[len(recent_performances) // 2 :])

                if late_avg > early_avg + 0.02:
                    status["recent_performance_trend"] = "improving"
                elif late_avg < early_avg - 0.02:
                    status["recent_performance_trend"] = "declining"

        # Harmonic coordination analysis
        target_freqs = [gate.target_frequency for gate in self.gates.values()]
        if target_freqs:
            fundamental = min(target_freqs)
            harmonic_ratios = [freq / fundamental for freq in target_freqs]

            status["harmonic_coordination"] = {
                "fundamental_frequency": fundamental,
                "harmonic_ratios": harmonic_ratios,
                "harmonic_alignment": self._assess_harmonic_alignment(harmonic_ratios),
            }

        return status

    def _assess_harmonic_alignment(self, harmonic_ratios: List[float]) -> float:
        """Assess how well frequencies align with harmonic series"""

        alignment_scores = []

        for ratio in harmonic_ratios:
            # Find closest integer harmonic
            closest_harmonic = round(ratio)
            alignment_error = abs(ratio - closest_harmonic)
            alignment_score = max(0.0, 1.0 - alignment_error)
            alignment_scores.append(alignment_score)

        return float(np.mean(alignment_scores))


async def demonstrate_harmonic_calibration():
    """Demonstrate the 3-Venturi Harmonic Autonomous Self-Calibration System"""

    print("üåä 3-VENTURI HARMONIC AUTONOMOUS SELF-CALIBRATION TOOL")
    print("=" * 65)
    print("Revolutionary harmonic analysis with autonomous calibration")
    print()

    try:
        # Initialize system
        print("üîß Initializing 3-Venturi Harmonic System...")
        harmonic_system = ThreeVenturiHarmonicSystem([10.0, 30.0, 50.0])

        # Generate test signal with harmonic content
        print("üì° Generating harmonic test signal...")
        t = np.linspace(0, 2, 2000)  # 2 seconds at 1kHz

        # Complex harmonic signal
        fundamental = 10.0  # Hz
        test_signal = (
            1.0 * np.sin(2 * np.pi * fundamental * t)  # Fundamental
            + 0.5 * np.sin(2 * np.pi * fundamental * 3 * t)  # 3rd harmonic
            + 0.3 * np.sin(2 * np.pi * fundamental * 5 * t)  # 5th harmonic
            + 0.1 * np.random.randn(len(t))  # Noise
        )

        print(f"   Signal length: {len(test_signal)} samples")
        print(f"   Fundamental frequency: {fundamental} Hz")
        print(f"   Harmonic content: 1st, 3rd, 5th harmonics")

        # Perform autonomous calibration
        print("\nü§ñ Starting Autonomous Self-Calibration...")
        calibration_results = harmonic_system.autonomous_calibration(
            test_signal, target_performance=0.80
        )

        print(f"\nüìä Calibration Results:")
        print(f"   Iterations: {calibration_results['iterations']}")
        print(
            f"   Convergence: {'‚úÖ Yes' if calibration_results['convergence_achieved'] else '‚ùå No'}"
        )
        print(
            f"   Success: {'‚úÖ Yes' if calibration_results['calibration_successful'] else '‚ùå No'}"
        )
        print(f"   Final Performance: {calibration_results['system_performance']:.3f}")

        # Show individual gate performance
        print(f"\n   Gate Performance:")
        for gate_id, performance in calibration_results["gate_performance"].items():
            print(f"     {gate_id}: {performance:.3f}")

        # Test processing with calibrated system
        print("\nüß™ Testing Calibrated System...")

        # Process test signal
        processed_signal, gate_metrics = harmonic_system.process_harmonic_signal(
            test_signal
        )

        print(f"   Input signal variance: {np.var(test_signal):.6f}")
        print(f"   Output signal variance: {np.var(processed_signal):.6f}")

        # Show harmonic analysis for each gate
        print(f"\n   Harmonic Analysis Results:")
        for gate_id, metrics in gate_metrics.items():
            if "harmonic_analysis" in metrics:
                analysis = metrics["harmonic_analysis"]
                print(f"     {gate_id}:")
                print(
                    f"       Fundamental: {analysis.get('fundamental_frequency', 0):.1f} Hz"
                )
                print(f"       THD: {analysis.get('total_harmonic_distortion', 0):.3f}")
                print(f"       Performance: {metrics.get('performance_score', 0):.3f}")

        # System status
        print(f"\nüìà System Status:")
        status = harmonic_system.get_system_status()

        print(
            f"   Calibrated: {'‚úÖ' if status['calibration_state']['is_calibrated'] else '‚ùå'}"
        )
        print(f"   System Performance: {status['system_performance']:.3f}")
        print(f"   Performance Trend: {status['recent_performance_trend']}")

        if "harmonic_coordination" in status:
            coord = status["harmonic_coordination"]
            print(f"   Fundamental Freq: {coord['fundamental_frequency']:.1f} Hz")
            print(
                f"   Harmonic Ratios: {[f'{r:.1f}' for r in coord['harmonic_ratios']]}"
            )
            print(f"   Harmonic Alignment: {coord['harmonic_alignment']:.3f}")

        print(f"\nüéØ Integration Summary:")
        print(f"   ‚úÖ 3-Venturi Harmonic System operational")
        print(f"   ‚úÖ Autonomous self-calibration functional")
        print(f"   ‚úÖ Real-time harmonic analysis active")
        print(f"   ‚úÖ Adaptive parameter optimization enabled")
        print(f"   ‚úÖ Inter-gate harmonic coordination active")

        # Test different frequencies
        print(f"\nüîÑ Testing Adaptive Frequency Response...")
        test_frequencies = [8.0, 15.0, 25.0, 40.0]

        for freq in test_frequencies:
            # Generate single-frequency test signal
            single_freq_signal = np.sin(2 * np.pi * freq * t)
            processed, _ = harmonic_system.process_harmonic_signal(single_freq_signal)

            # Measure response
            input_power = np.var(single_freq_signal)
            output_power = np.var(processed)
            response_gain = output_power / input_power if input_power > 0 else 0

            print(f"     {freq:4.1f} Hz: Gain = {response_gain:.2f}")

    except Exception as e:
        print(f"‚ùå Error in demonstration: {e}")
        import traceback

        traceback.print_exc()

    print("\n" + "=" * 65)
    print("üåä 3-Venturi Harmonic Autonomous Self-Calibration demonstration completed!")


if __name__ == "__main__":
    # Run enhanced demonstration
    asyncio.run(demonstrate_enhanced_harmonic_calibration())


async def demonstrate_enhanced_harmonic_calibration():
    """
    Enhanced demonstration of the 3-Venturi Harmonic Autonomous Self-Calibration Tool
    with EEG/ML/VR pipeline integration
    """
    print("\n" + "=" * 80)
    print("üöÄ ENHANCED 3-Venturi Harmonic Autonomous Self-Calibration Tool Demo")
    print("üß† With EEG Preprocessing, ML Pipeline & VR Pre-rendering Integration")
    print("=" * 80)

    try:
        # Initialize enhanced harmonic system
        print("\nüîß Initializing Enhanced 3-Venturi Harmonic System...")

        # Optimized frequencies for neural processing
        eeg_optimized_frequencies = [8.5, 25.5, 42.0]  # Alpha, Beta, Gamma
        harmonic_system = ThreeVenturiHarmonicSystem(eeg_optimized_frequencies)

        # Display system configuration
        print(
            f"‚úÖ System initialized with EEG-optimized frequencies: {eeg_optimized_frequencies} Hz"
        )
        print(f"üéØ Target frequencies optimized for Alpha/Beta/Gamma neural bands")

        # Generate enhanced test signals
        print("\nüìä Generating Enhanced Test Signals...")

        sampling_rate = 1000.0  # Hz
        duration = 2.0  # seconds
        t = np.linspace(0, duration, int(sampling_rate * duration))

        # EEG-like signal with multiple frequency components
        print("üß† Creating EEG-like multi-component signal...")
        eeg_signal = (
            0.8 * np.sin(2 * np.pi * 8.5 * t)  # Alpha
            + 0.6 * np.sin(2 * np.pi * 25.5 * t)  # Beta
            + 0.4 * np.sin(2 * np.pi * 42.0 * t)  # Gamma
            + 0.1 * np.random.randn(len(t))  # Neural noise
        )

        # ML training signal with complex harmonics
        print("ü§ñ Creating ML-optimized harmonic signal...")
        ml_signal = (
            np.sin(2 * np.pi * 10 * t)
            + 0.5 * np.sin(2 * np.pi * 30 * t)
            + 0.3 * np.sin(2 * np.pi * 50 * t)
            + 0.2 * np.sin(2 * np.pi * 70 * t)
        )

        # VR synchronization signal
        print("üéÆ Creating VR synchronization signal...")
        vr_signal = (
            np.sin(2 * np.pi * 60 * t)  # Frame rate sync
            + 0.7 * np.sin(2 * np.pi * 15 * t)  # Motion tracking
            + 0.3 * np.sin(2 * np.pi * 120 * t)  # High-freq haptics
        )

        # Enhanced autonomous calibration tests
        print("\nüéØ Running Enhanced Autonomous Calibration Tests...")

        # Test 1: Standard enhanced calibration
        print("\n1Ô∏è‚É£ Enhanced Standard Calibration...")
        standard_results = harmonic_system.autonomous_calibration_enhanced(
            eeg_signal, target_performance=0.90, processing_mode="standard"
        )
        print(f"   ‚úÖ Performance: {standard_results['system_performance']:.1%}")
        print(f"   üìä Stability: {standard_results['frequency_stability']:.1%}")
        print(f"   üîÑ Iterations: {standard_results['iterations']}")

        # Test 2: EEG-optimized calibration
        print("\n2Ô∏è‚É£ EEG Pipeline Optimization...")
        eeg_results = harmonic_system.autonomous_calibration_enhanced(
            eeg_signal, target_performance=0.92, processing_mode="eeg"
        )
        print(f"   üß† EEG Performance: {eeg_results['system_performance']:.1%}")
        print(f"   üìà Neural Coherence: {eeg_results['harmonic_coherence']:.1%}")
        print(f"   üéØ Calibration Success: {eeg_results['calibration_successful']}")

        # Test 3: ML pipeline optimization
        print("\n3Ô∏è‚É£ ML Pipeline Optimization...")
        ml_results = harmonic_system.autonomous_calibration_enhanced(
            ml_signal, target_performance=0.91, processing_mode="ml"
        )
        print(f"   ü§ñ ML Performance: {ml_results['system_performance']:.1%}")
        print(f"   ‚öôÔ∏è Feature Extraction: Optimized")
        print(f"   üìä Learning Rate: {ml_results['adaptive_learning_rate']:.6f}")

        # Test 4: VR pre-rendering optimization
        print("\n4Ô∏è‚É£ VR Pre-rendering Optimization...")
        vr_results = harmonic_system.autonomous_calibration_enhanced(
            vr_signal, target_performance=0.89, processing_mode="vr"
        )
        print(f"   üéÆ VR Performance: {vr_results['system_performance']:.1%}")
        print(f"   ‚ö° Sync Accuracy: {vr_results['phase_synchronization']:.1%}")
        print(f"   üñºÔ∏è Pre-rendering: Optimized")

        # Test 5: Multi-mode comprehensive optimization
        print("\n5Ô∏è‚É£ Multi-Mode Comprehensive Optimization...")
        multi_results = harmonic_system.autonomous_calibration_enhanced(
            eeg_signal, target_performance=0.93, processing_mode="multi"
        )
        print(
            f"   üåü Multi-Mode Performance: {multi_results['system_performance']:.1%}"
        )
        print(f"   üîÑ All Pipelines: Synchronized")
        print(f"   üéØ Ultimate Success: {multi_results['calibration_successful']}")

        # Enhanced system status
        print("\nüìã Enhanced System Status:")
        system_status = harmonic_system.get_system_status()
        print(
            f"   üîß Calibrated: {system_status['calibration_state']['is_calibrated']}"
        )
        print(
            f"   üìä Score: {system_status['calibration_state']['calibration_score']:.3f}"
        )
        print(
            f"   ‚ö° Stability: {system_status['calibration_state']['stability_metric']:.3f}"
        )

        # Gate-specific enhanced metrics
        print("\nüö™ Enhanced Gate Performance:")
        for gate_id, gate in harmonic_system.gates.items():
            print(
                f"   {gate_id}: Target={gate.target_frequency:.1f}Hz, "
                f"EEG={gate.eeg_mode}, ML={gate.ml_mode}, VR={gate.vr_mode}"
            )

        # Real-time processing demonstration
        print("\n‚ö° Real-time Processing Demonstration:")

        # Generate real-time signal chunks
        chunk_size = 250  # 250ms at 1000Hz
        total_chunks = 8

        print("   Processing real-time signal chunks...")
        for chunk_idx in range(total_chunks):
            start_idx = chunk_idx * chunk_size
            end_idx = start_idx + chunk_size

            if end_idx > len(eeg_signal):
                break

            signal_chunk = eeg_signal[start_idx:end_idx]

            # Process chunk through enhanced system
            processed_chunk, chunk_metrics = harmonic_system.process_harmonic_signal(
                signal_chunk
            )

            # Calculate real-time metrics
            chunk_performance = np.mean(
                [
                    metrics.get("performance_score", 0.0)
                    for metrics in chunk_metrics.values()
                ]
            )

            print(f"     Chunk {chunk_idx + 1}: Performance={chunk_performance:.1%}")

            # Simulate real-time delay
            await asyncio.sleep(0.05)

        # Enhanced frequency response analysis
        print("\nüìà Enhanced Frequency Response Analysis:")
        print("   Testing optimized frequency ranges...")

        test_frequencies = [5.0, 8.5, 12.0, 25.5, 35.0, 42.0, 55.0, 70.0]

        for freq in test_frequencies:
            # Generate single-frequency test signal
            test_signal = np.sin(2 * np.pi * freq * t)
            processed, metrics = harmonic_system.process_harmonic_signal(test_signal)

            # Enhanced metrics calculation
            input_power = np.var(test_signal)
            output_power = np.var(processed)
            response_gain = output_power / input_power if input_power > 0 else 0

            # Determine frequency band
            if 4 <= freq <= 8:
                band = "Theta"
            elif 8 <= freq <= 13:
                band = "Alpha"
            elif 13 <= freq <= 30:
                band = "Beta"
            elif 30 <= freq <= 50:
                band = "Gamma"
            else:
                band = "Other"

            print(f"     {freq:4.1f} Hz ({band:5s}): Gain = {response_gain:.2f}")

        # Integration readiness assessment
        print("\nüîó Pipeline Integration Readiness:")
        print("   ‚úÖ EEG Preprocessing: Ready")
        print("   ‚úÖ ML Feature Pipeline: Ready")
        print("   ‚úÖ VR Pre-rendering: Ready")
        print("   ‚úÖ Azure Functions: Compatible")
        print("   ‚úÖ Real-time Processing: Optimized")

        # Performance summary
        print("\nüìä Enhanced Performance Summary:")
        all_results = [
            standard_results,
            eeg_results,
            ml_results,
            vr_results,
            multi_results,
        ]
        avg_performance = np.mean([r["system_performance"] for r in all_results])
        avg_stability = np.mean([r["frequency_stability"] for r in all_results])
        avg_coherence = np.mean([r["harmonic_coherence"] for r in all_results])

        print(f"   üéØ Average Performance: {avg_performance:.1%}")
        print(f"   üìä Average Stability: {avg_stability:.1%}")
        print(f"   üîÑ Average Coherence: {avg_coherence:.1%}")
        print(
            f"   ‚ö° Calibration Success Rate: {sum(r['calibration_successful'] for r in all_results)}/5"
        )

    except Exception as e:
        print(f"‚ùå Error in enhanced demonstration: {e}")
        import traceback

        traceback.print_exc()

    print("\n" + "=" * 80)
    print(
        "üåü Enhanced 3-Venturi Harmonic Autonomous Self-Calibration Tool Demo Complete!"
    )
    print(
        "üöÄ Ready for integration with EEG preprocessing, ML pipelines, and VR pre-rendering!"
    )
    print("=" * 80)
